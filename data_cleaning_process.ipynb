{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3290 entries, 0 to 3289\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Aircraft Type           1896 non-null   object \n",
      " 1   Users Reviews           3290 non-null   object \n",
      " 2   Country                 3289 non-null   object \n",
      " 3   Type_of_Travellers      2887 non-null   object \n",
      " 4   Route                   2883 non-null   object \n",
      " 5   Seat_Types              3287 non-null   object \n",
      " 6   Seat Comfort            3176 non-null   float64\n",
      " 7   Date Flown              2880 non-null   object \n",
      " 8   Cabin Staff Service     3165 non-null   float64\n",
      " 9   Ground Service          2812 non-null   float64\n",
      " 10  Food & Beverages        2911 non-null   float64\n",
      " 11  Wifi & Connectivity     592 non-null    float64\n",
      " 12  Inflight Entertainment  2171 non-null   float64\n",
      " 13  Value For Money         3290 non-null   int64  \n",
      " 14  Recommended             3290 non-null   object \n",
      "dtypes: float64(6), int64(1), object(8)\n",
      "memory usage: 385.7+ KB\n",
      "None\n",
      "\n",
      "Duplicate Rows Count:\n",
      "Aircraft Type              2\n",
      "Users Reviews             63\n",
      "Country                   63\n",
      "Type_of_Travellers         2\n",
      "Route                      2\n",
      "Seat_Types                62\n",
      "Seat Comfort              63\n",
      "Date Flown                 2\n",
      "Cabin Staff Service       63\n",
      "Ground Service             2\n",
      "Food & Beverages          63\n",
      "Wifi & Connectivity        0\n",
      "Inflight Entertainment    63\n",
      "Value For Money           63\n",
      "Recommended               63\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "reviews = pd.read_csv(\"Airlines_User-Reviews_Raw.csv\")\n",
    "\n",
    "# Display general information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(reviews.info())\n",
    "\n",
    "# Check for duplicate rows and display counts\n",
    "duplicates_count = reviews.count() - reviews.drop_duplicates().count()\n",
    "print(\"\\nDuplicate Rows Count:\")\n",
    "print(duplicates_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "### Duplicates \n",
    "\n",
    "##### Identifying and Handling Duplicates:\n",
    "\n",
    "While cleaning the dataset, it's crucial to consider which entities can have duplicates and which need to be preserved for meaningful analysis. Let's explore some entities and discuss the approach to handling duplicates:\n",
    "\n",
    "#### Aircraft Type:\n",
    "\n",
    "Aircraft type information is crucial for understanding the context of user reviews. Duplicates in this category might indicate repeated issues or experiences with specific aircraft models. It's advisable to retain duplicates for this entity to capture patterns associated with different aircraft types.\n",
    "Users Reviews:\n",
    "\n",
    "User reviews are the core of sentiment analysis, and duplicates in this context may arise due to users sharing similar experiences. However, the presence of duplicates doesn't necessarily diminish their value. Retaining duplicate reviews allows for a more comprehensive sentiment analysis, capturing common sentiments expressed by multiple users.\n",
    "Country, Type_of_Travellers, Route, Seat_Types, etc.:\n",
    "\n",
    "These entities provide additional context to user reviews. While exact duplicates may not offer unique insights, subtle variations could be significant. For instance, the same route flown by different types of travelers might yield diverse experiences. It's essential to carefully assess duplicates in these categories.\n",
    "Date Flown:\n",
    "\n",
    "Duplicates based on the date flown might be indicative of recurring issues during specific time periods. Retaining duplicates for this entity enables the identification of trends or recurring problems associated with particular dates.\n",
    "Approach to Handling Duplicates:\n",
    "\n",
    "#### Identify Unique Identifiers:\n",
    "\n",
    "Before deciding on duplicate handling, identify unique identifiers that distinguish between similar entities. For example, if two reviews seem similar, check if there are differences in other attributes like date, country, or aircraft type.\n",
    "\n",
    "#### Retain for Contextual Analysis:\n",
    "\n",
    "Consider retaining duplicates for entities like \"Aircraft Type,\" \"Users Reviews,\" and other relevant categories to preserve context for deeper analysis.\n",
    "Consolidate or Remove Exact Duplicates:\n",
    "\n",
    "For entities where exact duplicates provide limited value (e.g., exact duplicates in \"Users Reviews\"), you may choose to consolidate or remove them. This ensures that each unique sentiment contributes meaningfully to the analysis.\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "Balancing the retention and removal of duplicates is a nuanced process. The decision depends on the specific objectives of your analysis and the nature of the dataset. By carefully evaluating duplicates, you can enhance the quality of insights derived from the dataset and provide a more accurate understanding of user experiences in the airline industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Retain duplicates for contextual analysis\u001b[39;00m\n\u001b[1;32m      2\u001b[0m contextual_duplicates_cols \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mAircraft Type\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDate Flown\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m contextual_duplicates \u001b[39m=\u001b[39m reviews\u001b[39m.\u001b[39mduplicated(subset\u001b[39m=\u001b[39mcontextual_duplicates_cols, keep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m contextual_duplicates_df \u001b[39m=\u001b[39m reviews[contextual_duplicates]\n\u001b[1;32m      6\u001b[0m \u001b[39m# Consolidate or remove exact duplicates\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews' is not defined"
     ]
    }
   ],
   "source": [
    "# Retain duplicates for contextual analysis\n",
    "contextual_duplicates_cols = [\"Aircraft Type\", \"Date Flown\"]\n",
    "contextual_duplicates = reviews.duplicated(subset=contextual_duplicates_cols, keep=False)\n",
    "contextual_duplicates_df = reviews[contextual_duplicates]\n",
    "\n",
    "# Consolidate or remove exact duplicates\n",
    "reviews = reviews.drop_duplicates()\n",
    "\n",
    "# Handle variations in categorical data\n",
    "reviews[\"Country\"] = reviews[\"Country\"].str.lower()  # Example: Standardize country names to lowercase\n",
    "\n",
    "# Address null values\n",
    "# For demonstration purposes, fill null values with a placeholder\n",
    "reviews = reviews.fillna(\"Not Available\")\n",
    "\n",
    "# Document cleaning steps in a log\n",
    "cleaning_log = \"\"\"\n",
    "Cleaning Steps Log:\n",
    "1. Identified unique identifiers: 'Aircraft Type', 'Date Flown'.\n",
    "2. Retained duplicates for contextual analysis in 'contextual_duplicates_df'.\n",
    "3. Consolidated or removed exact duplicates from 'reviews'.\n",
    "4. Handled variations in categorical data (e.g., standardized 'Country' to lowercase).\n",
    "5. Addressed null values by filling with a placeholder.\n",
    "\"\"\"\n",
    "\n",
    "# Save cleaned dataset to a new CSV file\n",
    "reviews.to_csv(\"Airlines_User-Reviews_Cleaned.csv\", index=False)\n",
    "\n",
    "# Display cleaning log\n",
    "print(cleaning_log)\n",
    "print(\"Cleaning completed. Cleaned dataset saved to 'Airlines_User-Reviews_Cleaned.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
